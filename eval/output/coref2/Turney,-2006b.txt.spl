we conclude that there are enough near analogies in the 374 sat questions for attributional similarity to perform better than random guessing , but not enough near analogies for attributional similarity to perform as well as relational similarity .
the performance of lra is significantly better than the lexicon-based approach of veale -LRB- 2004 -RRB- -LRB- see section 3.1 -RRB- and
as mentioned in the introduction , lra extends the vsm approach of turney and littman -LRB- 2005 -RRB- by -LRB- 1 -RRB- exploring variations on the analogies by replacing words with synonyms -LRB- step 1 -RRB- , -LRB- 2 -RRB- automatically generating connecting patterns -LRB- step 4 -RRB- , and -LRB- 3 -RRB- smoothing the data with svd -LRB- step 9 -RRB- .
the novelty in turney and littman -LRB- 2005 -RRB- is that their patterns are not used to mine text for instances of word pairs that fit the patterns -LRB- hearst , 1992 ; berland and charniak , 1999 -RRB- ; instead , they are used to gather frequency data for building vectors that represent the relation between a given pair of words .
the single nearest neighbor algorithm is a supervised learning algorithm -LRB- i.e. , it requires a training set of labeled data -RRB- , but we are using lra to measure the distance between a pair and its potential neighbors , and lra is itself determined in an unsupervised fashion -LRB- i.e. , lra does not need labeled data -RRB- .
