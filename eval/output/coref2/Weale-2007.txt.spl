in this paper , we propose to use wikipedia to extract the hidden information in entities for more accurate classification than would be able if we used surface features alone .
additionally , they observe that since their algorithm is language independent , additional languages can be added by simply running their algorithm over the appropriate wikipedia language set .
these entities are then matched -LRB- if possible -RRB- to a wikipedia article , where the category information is used to generate the document features .
to do this , we run an named entity recognizer over each document in the corpus and extract the named entities to be used for article matching .
the evaluation of our method was done on a toy corpus consisting of 40 training documents -LRB- 30 positive \/ 10 negative -RRB- and 4 testing documents -LRB- 2 positive \/ 2
we ran the lingpipe named entity recognizer2 over our data set in order to get our named entities , an off-the-shelf named entity recognizer .
we then reconfigured our training examples based on the results of the entity recognition process , resulting in a 28 positive \/ 12 negative training split .
in this paper , we have introduced a method for document categorization using wikipedia as a large - scale knowledge base for information about named entities .
