we will consider our training set to consist of -LRB- p , k , c -RRB- triples : one for each pronoun , where p is the pronoun to be resolved , k is the pronouns context , and c is a candidate list containing the nouns p could potentially be resolved to .
ems role is to induce a probability distribution over candidates to maximize the likelihood of the -LRB- p , k -RRB- pairs observed in our training set : to improve our ability to generalize to future cases , we use a naive bayes assumption to state that the choices of pronoun and context are conditionally independent , given an antecedent .
if we assume that l and j are independent , and that p and k each depend only on the l component of c , we can combine equations 3 and 4 to get our final formulation for the joint probability distribution : the jump term j , though important when resolving pronouns , is not likely to be correlated with
the columns split the results into three cases : all pronouns with no exceptions ; all cases where the pronoun was found in a sentence containing no quotation marks -LRB- and therefore resembling the training data provided to em -RRB- ; and finally all pronouns excluded by the second case .
