the
the probability of a sentence is now : we make one further simplification before beginning to approximate : we first generate the set of syntactic slots ri which we intend to fill with known entities , and then decide which entities from the known set to select .
the emission model of each state is an instance of the relaxed entity grid model as described above , but in addition to conditioning on the role and history , we condition also on the state and on the particular set of lexical items lex -LRB- ki -RRB- which may be selected to fill the role : p -LRB- r + _ ej i r , ~ rh -LRB- i-1 -RRB- , j , qi , lex -LRB- ki -RRB- -RRB- .
the actual number of states found by the model depends mostly on the backoff constants , the ^ s -LRB- and , for pitman-yor processes , discounts -RRB- chosen for the emission models -LRB- the entity grid , non-entity word model and new noun model -RRB- , and is relatively insensitive to particular choices of prior for the other hyperparameters .
in the sentence ordering task , -LRB- lapata , 2003 ; barzilay and lee , 2004 ; barzilay and lapata , 2005 ; soricut and marcu , 2006 -RRB- , we view a document as an unordered bag of sentences and try to find the ordering of the sentences which maximizes coherence according to our model .
