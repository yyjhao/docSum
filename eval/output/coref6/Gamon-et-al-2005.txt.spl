the data set shows a clear skew towards positive reviews : in the annotated data set , positive sentences comprise 62.33 % of the data , sentences of type other comprise 23.27 % , and negative sentences 14.4 % .
by choosing a menu option , the user can view a summary of the clusters in the form of simple top five lists , where for a given make \/ model the top five terms overall , the top five positive terms and the top five negative terms are displayed .
once the sentences for a make and model of car have been assigned to clusters and have received a sentiment score from the sentiment classifier , the visualization component -LRB- section 3.1 -RRB- displays the clusters and the keyword labels that were produced for the sentences associated with that car .
however , the following characteristics of the car reviews data set rendered techniques previously cited in the literature unsuited to our task : since we are aiming at sentence-level classification , we are dealing with much shorter textual units than the full movie reviews , which range
we implemented a modified version of nigam et al. s algorithm for training a naive bayes classifier using expectation maximization -LRB- em -RRB- and bootstrapping from a small set of labeled data to a large set of unlabeled data -LSB- 14 -RSB- .
