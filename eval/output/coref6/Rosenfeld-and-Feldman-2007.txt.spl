in table 5 we show further details for several top clusters : we list two candidate pairs -LRB- alphabetically first -RRB- placed into the cluster , and a single context -LRB- chronologically first -RRB- extracted for each listed candidate .
we extend this similarity to similarity between candidates by defining their representation as follows : for similarity between two vectors in the feature space we use the common cosine measure which ignores the relative lengths of vectors .
we compare several clustering algorithms , and several feature extraction and selection methods , evaluating them using a novel evaluation metric , which is adapted for evaluating precision-oriented uri clustering results .
they used a complete-linkage hierarchical clustering algorithm , with a very simple representation of contexts the features were the
in our experiments we surprisingly found that the single linkage hac not only outperforms both the hac with other linkage types and the k-means , but also has a natural stopping criterion : stop merging the clusters when the average similarity between the datapoints of the clusters being merged becomes smaller than ^ times the maximal similarity between them , where ^ &lt; 1 is a constant , for which we use 1 \/ 2 .
we test and compare two common general-purpose clustering algorithms in our experiments : the hierarchical agglomerative clustering -LRB- hac -RRB- algorithm , and the partitioning k-means algorithm .
