by saying that words that can be reliably attached to image regions are easy to recognize and those that can not , are not ; and which objects are indistinguishable using our features ?
evaluation method : each image in the test set is automatically annotated , by taking every region larger than the threshold , quantizing the region to a blob , and using the lexicon to determine the most likely word given that blob ; if the probability of the word given the blob is greater than the relevant threshold , then the image is annotated with that word .
this can occur because one word is a modifier for example , in our data set , polar reliably predicts bear or because of some relation between the concepts for example , in our data set , either mare or foals almost quite reliably predicts horses but in either case , there is no prospect of learning the correspondence properly .
to compare two words , we use the symmetrised kullbackleibler -LRB- kl -RRB- divergence between the conditional probability of blobs , given the words .
table 3 shows that we have some very nice clusters which have strong semantic or visual relations like kit-horses-mare-foals , leaf-flowers-plants-vegetables or pool-athlete-vines-swimmers and the results are better when we cluster the words -LRB- compare with table 1 -RRB- .
