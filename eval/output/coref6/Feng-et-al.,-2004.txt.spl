this model simultaneously learns the joint probabilities of associating words with image features using a training set of images with keywords and then generates multiple probabilistic annotations for each image .
however , using a rectangular grid -LRB- with more regions than produced by the segmentation -RRB- allows the model to learn using a much larger set of training
we tested the algorithms using two different datasets , the corel data set from duygulu et al -LSB- 5 -RSB- and a set of video key frames from nist s video trec -LSB- 12 -RSB- .
given a new -LRB- un-annotated -RRB- image we can split it into regions ra , compute feature vectors 91 ... 9n for each region and then use equation 1 to determine what subset of vocabulary w \* is most likely to co-occur with the set of feature vectors : equation -LRB- 3 -RRB- arises out of placing a gaussian kernel over the feature vector 9i of every region of image j. each kernel is parametrized by the feature covariance matrix e. as a matter of convenience we assumed e = 0 i , where i is the identity matrix .
we then learn a joint probability model for -LRB- continuous -RRB- image features and words called a relevance model and use this model to annotate test images which we have not seen .
