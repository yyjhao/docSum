in addition to exhibiting better predictive performance than either mackay and petos language model or latent dirichlet allocation , the topics inferred using the new model are typically less dominated by function words than are topics inferred from the same corpora using latent dirichlet allocation .
since word generation is conditioned upon both j and k in the new model presented in this paper , there is more than one way in which hyperparameters for the prior over 4 -RRB- might be shared in this model .
in my implementation , each fixed-point iteration takes time that is proportional to s and -LRB- at worst -RRB- n. for latent dirichlet allocation and the new model with prior 1 , the time taken to perform the m-step is therefore at worst proportional to s , n and the number of iterations taken to reach convergence .
in latent dirichlet allocation , the latent topic for a given word is inferred using the identity of the word , the number of times the word has previously been assumed to be generated by each topic , and the number of times each topic has been used in the current document .
such models typically fall into one of two categoriesthose that generate each word on the basis of some number of
