a potential advantage of this approach is that the mapreduce framework can use a combiner to group many -LRB- a , b -RRB- pairs into a single value before the key \/ value pair leaves for the reducer .4 if the underlying distribution from which pairs -LRB- a , b -RRB- has certain characteristics , this can result in a significant reduction in the number of keys that the mapper emits -LRB- although the number of statistics will be identical -RRB- .
method 2 requires more data
assuming a given sentence length m for f ' 1 , the translation probability is defined as follows : in this section , we consider the mapreduce implementation of two specific alignment models : estimating the parameters for these models is more difficult -LRB- and more computationally expensive -RRB- than with the models considered in the previous section : rather than simply being able to count the word pairs and alignment relationships and estimate the models directly , we must use an existing model to compute the expected counts for all possible alignments , and then use these counts to update the new model .7 this training strategy is referred to as expectation - maximization -LRB- em -RRB- and is guaranteed to always improve the quality of the prior model at each iteration -LRB- brown et al. , 1993 ; dempster et al. , 1977 -RRB- .
