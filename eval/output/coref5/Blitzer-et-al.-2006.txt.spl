however , in many situations we may have a source domain with plentiful labeled training data , but we need to process material from a target domain with a different distribution from the source domain and no labeled data .
in such cases , we must take steps to adapt a model trained on the source domain for use in the target domain -LRB- roark and bacchiani , 2003 ; florian et al. , 2004 ; chelba and acero , 2004 ; ando , 2004 ; lease and charniak , 2005 ; daume iii and marcu , 2006 -RRB- .
if we have designed the pivots well , then 0 should encode correspondences among features from different domains which are important for the supervised task , and the classifier we train using these new features on the source domain will perform well on the target domain .
3.1 pivot features pivot features should occur frequently in the unlabeled data of both domains , since we must estimate their covariance with non-pivot features accurately , but they must also be diverse enough to adequately characterize the nuances of the supervised task .
with 1000 source domain sentences and 50 target domain sentences , using scl tagger features gives a 20.4 % relative reduction in error over using supervised tagger features and a 39.9 % relative reduction in error over using no source features .
