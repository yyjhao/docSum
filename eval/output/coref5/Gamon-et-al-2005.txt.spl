however , the following characteristics of the car reviews data set rendered techniques previously cited in the literature unsuited to our task : since we are aiming at sentence-level classification , we are dealing with much shorter textual units than the full
the input to the clustering algorithm is the set of sentences s for which clusters are to be extracted , a stop-list wstop of words around which clusters ought not to be created , and -LRB- optionally -RRB- a go list wgo of words known to be salient in the domain .
once the sentences for a make and model of car have been assigned to clusters and have received a sentiment score from the sentiment classifier , the visualization component -LRB- section 3.1 -RRB- displays the clusters and the keyword labels that were produced for the sentences associated with that car .
the other category was applied to sentences with no discernible sentiment , as well as to sentences that expressed both positive and negative sentiment and sentences with sentiment that can not be deduced without taking context and \/ or world knowledge into account .
the data set shows a clear skew towards positive reviews : in the annotated data set , positive sentences comprise 62.33 % of the data , sentences of type other comprise 23.27 % , and negative sentences 14.4 % .
