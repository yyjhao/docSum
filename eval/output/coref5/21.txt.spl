we present two conceptually different machine learning approaches -LSB- lmr04a -RSB- , compare them to existing approaches and show that
in its most general form , our model assumes : -LRB- 1 -RRB- a joint distribution over entities , so that a document that mentions president kennedy is more likely to mention oswald or white house than roger clemens ; -LRB- 2 -RRB- an author model , which makes sure that at least one mention of a name in a document is easily identifiable -LRB- after all , that is the authors goal -RRB- , and then generates other mentions via -LRB- 3 -RRB- an appearance model , governing how mentions are transformed from the representative mention .
in addition to further studies of the discriminative model , including going beyond the current noisy supervision -LRB- given at a global annotation level , although learning is done locally -RRB- , exploring how much data is needed for a supervised model to perform as well as the unsupervised model , and whether the initialization of the unsupervised model can gain from supervision , there are several other critical issues we would like to address from the robust reading perspective .
our first model is a discriminative approach that models the problem as that of deciding whether any two names mentioned in a collection of documents represent the same entity .
