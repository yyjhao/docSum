when trained only on the 800 text-hypothesis pairs in the pascal 2006 development set -LRB- dev -RRB- , groundhog correctly classified 65.25 % of the examples in the test set ; when the classifier was trained on the more than 200,000 examples in lccs training corpora , performance was increased by 10 % .
four classes of features are extracted : -LRB- 1 -RRB- alignment features , which compare properties of aligned constituents , -LRB- 2 -RRB- dependency features , which compare entities and predicates using dependencies identified by a semantic parser , -LRB- 3 -RRB- paraphrase features , which determine whether passages extracted from the text and hypothesis match acquired paraphrases , and -LRB- 4 -RRB- semanticfeatures , which contrast semantic values assigned to predicates in each example sentence .
since performing this alignment requires access to large amounts of training data , this classifier is trained using two large corpora of positive and negative examples of textual entailment that we extracted from newswire corpora .
features from the alignment process and from the acquired paraphrases are used together with semantic
these annotations were used to train a hill - climber that was used to annotate a larger set of 450,000 alignment pairs selected at random from the training corpora described in section 4 that was then used to train a maximum entropy-based classifier that was used on the 2006 test set .
