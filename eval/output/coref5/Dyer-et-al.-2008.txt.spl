the graph in figure 3 shows the performance of the three problem decompositions on two model types we are estimating , conditional phrase translation probabilities -LRB- 1.5 m sentences , max phrase length = 7 -RRB- , and conditional lexical translation probabilities as found in a word alignment model -LRB- 500k sentences -RRB- .
a potential advantage of this approach is that the mapreduce framework can use a combiner to group many -LRB- a , b -RRB- pairs into a single value before the key \/ value pair leaves
assuming a given sentence length m for f ' 1 , the translation probability is defined as follows : in this section , we consider the mapreduce implementation of two specific alignment models : estimating the parameters for these models is more difficult -LRB- and more computationally expensive -RRB- than with the models considered in the previous section : rather than simply being able to count the word pairs and alignment relationships and estimate the models directly , we must use an existing model to compute the expected counts for all possible alignments , and then use these counts to update the new model .7 this training strategy is referred to as expectation - maximization -LRB- em -RRB- and is guaranteed to always improve the quality of the prior model at each iteration -LRB- brown et al. , 1993 ; dempster et al. , 1977 -RRB- .
