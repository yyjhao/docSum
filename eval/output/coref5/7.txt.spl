from the previous example , we form the pattern x is the largest y , where we replace the two words jaguar and cat by two wildcards x and y. our contributions in this paper are two fold : we propose an automatically extracted lexico-syntactic patterns-based approach to compute semantic similarity using text snippets obtained from a web search engine .
one must consider the page counts not just for the query p and q , but also for the individual words p and q to assess semantic similarity between p and q. we modify four popular co-occurrence measures ; jaccard , overlap -LRB- simpson -RRB- , dice , and pmi -LRB- point-wise mutual information -RRB- , to compute semantic similarity using page counts .
this function returns a vector of patterns where each element is the normalized frequency of the corresponding pattern in the snippets for the query a b. we append similarity scores calculated using page counts in section 3.2 to create the final feature vector f for the word - pair -LRB- a , b -RRB- .
we represent each snippet as a bag-of-words and calculate the similarity sim -LRB- sa , sb -RRB- between two snippets sa , sbas follows , in formula 15 isi denotes the number of words in snippet s. we used different semantic similarity measures for sim in formula 15 and employed the group average agglomerative clustering
