if one accounts for the upper bound in table 2 , our methods do very well on those
the majority of pronoun resolution approaches have thus far relied on manual intervention in the resolution process , such as using a manually-parsed corpus , or manually removing difficult non-anaphoric cases ; we follow -LRB- mitkov et al. -RRB- ' s approach -LRB- 2002 -RRB- with a fully-automatic pronoun resolution method .
ems role is to induce a probability distribution over candidates to maximize the likelihood of the -LRB- p , k -RRB- pairs observed in our training set : to improve our ability to generalize to future cases , we use a naive bayes assumption to state that the choices of pronoun and context are conditionally independent , given an antecedent .
the columns split the results into three cases : all pronouns with no exceptions ; all cases where the pronoun was found in a sentence containing no quotation marks -LRB- and therefore resembling the training data provided to em -RRB- ; and finally all pronouns excluded by the second case .
we will consider our training set to consist of -LRB- p , k , c -RRB- triples : one for each pronoun , where p is the pronoun to be resolved , k is the pronouns context , and c is a candidate list containing the nouns p could potentially be resolved to .
