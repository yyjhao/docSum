we are interested in models that can perform three tasks : modeling the joint distribution of an image and its caption , modeling the conditional distribution of words given an image , and modeling the conditional distribution of words given a particular region of an image .
given a corpus of image \/ caption data , d = -LCB- -LRB- rd , wd -RRB- -RCB- dd = 1 , we find maximum likelihood estimates of the model parameters with a variational em procedure that maximizes the lower bound on the log likelihood of the data induced by the variational approximation described above .
the independence assumptions of the corr-lda model are a compromise between the extreme correspondence enforced by the gm-mixture model , where the entire image and caption are conditional on the same factor , and the lack of correspondence in the gm-lda model , where the image regions and caption words can conceivably be conditional on two disparate sets of factors .
to evaluate how well a model fits the data , we computed the per-image average negative log likelihood of the
the joint distribution of the hidden factor z and the image \/ caption -LRB- r , w -RRB- is : given a fixed number of factors k and a corpus of images \/ captions , the parameters of a gm-mixture model can be estimated by the em algorithms .
