we compare the learning results produced
to represent a word , using the word sense information in the data , we extract all ancestors located at the cut-off level and higher for the corresponding word sense .
the data we use consist of 600 noun-modifier pairs , tagged with 30 semantic relations , grouped into 5 classes of relations by general similarity -LRB- barker 1998 -RRB- , -LRB- nastase &amp; szpakowicz 2003 -RRB- , -LRB- turney &amp; littman 2003 -RRB- : the words in the pairs from the dataset are also annotated with part of speech and wordnet 1.6 word senses .
semantic relations describe interactions between a noun and its modifiers -LRB- noun-modifier relations -RRB- , a verb and its arguments -LRB- case relations \/ semantic roles -RRB- , and two clauses .
moreover , the difference in results when using word sketches and when using non-annotated data in favor of word sketches indicate that when no word-sense information is available , corpus-based word descriptions are more informative and useful for the task of learning semantic relations .
looking at the results obtained with the different representation methods , we can conclude that we can detect successfully the temporal relation between words by looking at either of the following : individual word senses as described by wordnet , word meaning as described by its contexts , or the prepositions or paraphrases that connect the words in the pair .
