the latter are operationalized as weights on the ordering and adjacency of facts and are derived from a corpus of naturally occurring texts .
the remainder
the node which yields the highest conditional probability is selected and ordered ahead .
we operationalize entity-based coherence for text-to-text generation by simply keeping track of the nouns attested in a sentence without however taking personal pronouns into account .
in cases of noun compounds , only the compound head -LRB- i.e. , rightmost noun -RRB- was taken into account .
a small set of rules was used to identify organizations -LRB- e.g. , united laboratories inc . -RRB-
dependencies .
this is not surprising given that nl encapsulates notions of entity-based coherence , which is relatively important for our domain .
we carried out a one-way analysis of variance -LRB- anova -RRB- to examine the effect of different feature types .
each participant saw three texts randomly chosen from the pool of 12 texts .
we then compared the differences in the orderings generated by the model and participants using the best performing features from experiment 2 -LRB- i.e. , nl and vdnd -RRB- .
in this paper we proposed a data intensive approach to text coherence where constraints on sentence ordering are learned from a corpus of domain-specific texts .
we proposed kendall s ti as an automated method for evaluating the generated orders .
