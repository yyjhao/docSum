if we want to find images of people , when rank ordering these images by probability the second image would be preferred to the first although there is no reason for preferring one image over another .
as a result , an image i1 annotated with a single word face will assign all probability mass to that word , so p -LRB- faceii1 -RRB- = 1 .
at the same time , an image i2 annotated with two words face and person will split the probability mass , so p -LRB- faceii2 -RRB- = 12 .
equation -LRB- 1 -RRB- makes it evident how we can use mbrm for annotating new images or video frames .
for each region , features are computed and then blobs are generated by clustering the image features for these regions across images .
gm-mixture assumes a low-dimensional topology , leading to a fully-parametric model where 200 or so latent aspects are estimated using the em algorithm .
experimental results .
this means that the annotation length for key frames can vary widely .
then recall = c , and precision = a. to evaluate the system performance , recall and precision values are averaged over the testing words .
rank order is , therefore , very important for such applications .
given a query word , the system will return all the images which are automatically annotated with that word
