the simplest model of support vector machine is the maximal hard margin classifier .
we thus have the following proposition .
the difference between these two formulations is also readily revealed in their respective dual objective functions .
for example , it is not clear from the formulation how to choose margin normalization function f
a pseudo training dataset is generated by applying these rules on a set of unlabeled documents .
for svm , it is easier to measure the unfitness of the model to these training datasets .
experiments show this particular choice of function form is appropriate .
ideally , one could come up with such a short list with only an appropriate description of the category , but such description is not available for the datasets we use .
the total number of keywords that describe category c .
the pseudo datasets are always generated by applying the prior model on the testing sets .
usually the performance of svm increases when one adds more labeled examples .
note that the influence of prior knowledge on the final performance is decreasing when the number of true labeled examples is increasing .
for statistical learning methods like svm , using human prior knowledge can in principle reduce the need for larger training dataset .
