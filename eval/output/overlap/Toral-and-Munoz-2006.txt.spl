on the other hand there are entity gazetteers which contain entities themselves , which usually are proper nouns .
our aim is to find a method which allow us to automatically create and maintain entity gazetteers by extracting the necessary information from linguistic resources .
thus , if we are able to develop a language independent system , it can be used to create gazetteers for any language for which wikipedia is available .
finally , we apply a weighting algorithm which takes into account the amount of nouns in the definition identified as belonging to the different entity types considered and decides to which entity type the entry belongs .
moreover , the updating of the gazetteers is straightforward ; just by executing the procedure , the new entries in wikipedia -LRB- the entries that did not exist at the time the procedure was performed the last time -RRB- would be analyzed and from these set , the ones detected as entities would be added to the corresponding gazetteers .
therefore , we think that our method can be useful for the creation of gazetteers for languages in which ner gazetteers are not available but have wikipedia and wordnet resources .
as an example , we consider to use them to extract verb frequencies for the entity
