one commonly used probabilistic model for text clustering is the multinomial naive bayes model described in -LSB- 11 -RSB- , which models a document as a vector of words with each word generated independently by a multinomial probability distribution conditioned on the document s class -LRB- i.e. , conditioned on which cluster it belongs to -RRB- .
as we show below , our more elaborate speclustering model
the simple method inherits previous clustering results which the user gives her feedback upon and for removed clusters , we reset the initial value of p -LRB- si1di ; bt -RRB- by distributing the probability mass uniformly among all clusters and halving the probability for the cluster s. the joint method uses feedback jointly to initialize the model .
keyword selection favors words that occur in the cluster and don t appear in other clusters , so if a category contains many documents and gets spread out to several clusters , even the majority of documents in the cluster belong to that category , the keyword selection may give low scores to words belong to that category because those words appear in other clusters .
all 5 runs with cr or pp feedback , 4 runs with wx feedback and 3 runs with hx feedback outperform both naive bayes baseline and speclustering-bound without feedback .
