assuming a given sentence length m for f ' 1 , the translation probability is defined as follows : in this section , we consider the mapreduce implementation of two specific alignment models : estimating the parameters for these models is more difficult -LRB- and more computationally expensive -RRB- than with the models considered in the previous section : rather than simply being able to count the word pairs and alignment relationships and estimate the models directly , we must use an existing model to compute the expected counts for all possible alignments , and then use these counts to update the new model .7 this training strategy is referred to as expectation - maximization -LRB- em -RRB- and is guaranteed to always improve the quality of the prior model at each iteration -LRB- brown et al. , 1993 ; dempster et al. , 1977 -RRB- .
since the alignment models we are considering are fundamentally based on a lexical translation probability model , i.e. , the conditional probability distribution p -LRB- ei f -RRB- , we describe in some detail how em updates the parameters for this model .9 using the model parameters from the previous iteration -LRB- or starting from an arbitrary or heuristic set of parameters during the first iteration -RRB- , an expected count is computed for every l x m pair -LRB- ez7 fj -RRB- for each parallel sentence
