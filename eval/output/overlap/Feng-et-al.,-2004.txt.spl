we then learn a joint probability model for -LRB- continuous -RRB- image features and words called a relevance model and use this model to annotate test images which we have not seen .
this model simultaneously learns the joint probabilities of associating words with image features using a training set of images with keywords and then generates multiple probabilistic annotations for each image .
let v denote the annotation vocabulary , t denote the training set of annotated images , and let j be an element of t. according to the previous section j is represented as a set of image regions rj = -LCB- r1 ... rn -RCB- along with the corresponding annotation wj e -LCB- 0,1 -RCB- v. we assume that the process that generated j is based on two distinct probability distributions .
now let ra = 191 ... 9na -RCB- denote the feature vectors of some image a , which is not in the training set t. similarly , let wb be some arbitrary subset of v. we would like to model p -LRB- ra , wb -RRB- , the joint probability of observing an image defined by ra together with annotation words wb .
given a new -LRB- un-annotated -RRB- image we can split it into regions ra , compute feature vectors 91 ... 9n for each region and then use equation 1 to determine what subset of
