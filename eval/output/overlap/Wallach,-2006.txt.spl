such models typically fall into one of two categoriesthose that generate each word on the basis of some number of preceding words or word classes and those that generate words based on latent topic variables inferred from word correlations independent of the order in which the words appear .
in addition to exhibiting better predictive performance than either mackay and petos language model or latent dirichlet allocation , the topics inferred using the new model are typically less dominated by function words than are topics inferred from the same corpora using latent dirichlet allocation .
this section introduces a model that extends latent dirichlet allocation by incorporating a notion of word order , similar to that employed by mackay and petos hierarchical dirichlet language model .
this
in latent dirichlet allocation , the latent topic for a given word is inferred using the identity of the word , the number of times the word has previously been assumed to be generated by each topic , and the number of times each topic has been used in the current document .
firstly , the predictive accuracy of the new model , especially when using prior 2 , is significantly better than that of either latent dirichlet allocation or the hierarchical dirichlet language model .
