our algorithm is related to -LRB- barzilay and lee , 2004 -RRB- s approach to text segmentation , which uses a hidden markov model -LRB- hmm -RRB- to model
we use gibbs sampling , drawing the topic assignment for each word , zu , z , conditioned on all other topic assignments , z -LRB- u , z -RRB- , all topic change indicators , c , and all words , w ; and then drawing the topic change indicator for each utterance , cu , conditioned on all other topic change indicators , cu , all topic assignments z , and all words w .
of these lists , 40 contained the most indicative words for each of the 10 topics from different models : the topic segmentation model ; a topic model that had the same number of segments but with fixed evenly spread segmentation boundaries ; an equivalent with randomly placed segmentation boundaries ; and the hmm .
however , while hmm approaches allow a segmentation of the data by topic , they do not allow adaptively combining different topics into segments : while a new segment can be modelled as being identical to a topic that has already been observed , it can not be modelled as a combination of the previously observed topics .1 note that while -LRB- imai et al. , 1997 -RRB- s hmm approach allows topic mixtures , it requires supervision with hand-labelled topics .
