large tables lead to large data structures that require more resources and more time to process and , more importantly , effort directed in handling large tables could likely be more usefully employed
phrase translation model probabilities are features of the form : the forward phrase probabilities p -LRB- ~ tj ~ s -RRB- are not used as features , but only as a filter on the set of possible translations : for each source phrase s ~ that matches some ngram in s , only the 30 top-ranked translations t ~ according to p -LRB- ~ tj ~ s -RRB- are retained .
the idea behind significance pruning of phrasetables is that not all of the phrase pairs in a phrasetable are equally supported by the data and that many of the weakly supported pairs could be removed because : the chance of them occurring again might be low , and their occurrence in the given corpus may be the result of an artifact -LRB- a combination of effects where several estimates artificially compensate for one another -RRB- .
note that the removal of 1-count phrase pairs is subsumed by significance pruning with a threshold greater than a and many of the other simple approaches -LRB- from an implementation point of view -RRB- are more difficult to justify as simply as the above significance test .
