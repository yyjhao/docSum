for the sense collocation method , we experiment with a substitution method whereby we replace one constituent in a training nc instance by a similar word , and annotate the new instance with the same sr as the original nc .
third , we apply the sense collocation co-training method and re-run the sense
since the sense collocations in the expanded training data have been varied through the advent of hypernyms and sister words , the number of sense collocations in the expanded training data is much greater than that of the original training data -LRB- 937 vs. 16,676 -RRB- .
fourth , we apply the constituent similarity co - training method over the consolidated training data -LRB- from both sense collocation and constituent similarity co-training -RRB- with the threshold unchanged at 0.8 .
however , since the generated training instances are more likely to contain errors , we decrement the similarity values for generated training instances by 0.2 , to prefer predictions based on the original training instances .
4.2 architecture -LRB- ii -RRB- we perform iterative co-training as described in section 3.2 , with the slight variation that we hold off reducing the threshold if more than 10 % of the test instances are tagged on a given iteration , giving other test instances a chance to be tagged at a higher threshold level relative to newly generated training instances .
