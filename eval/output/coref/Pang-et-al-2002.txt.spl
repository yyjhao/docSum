this domain is experimentally convenient because there are large on-line collections of such reviews , and because reviewers often summarize their overall sentiment with a machine-extractable rating indicator , such as a number of stars ; hence , we did not need to hand-label the data for supervised learning or evaluation purposes .
these experiments also provide us with baselines for experimental comparison ; in particular , the third baseline of 69 % might actually be considered somewhat difficult to beat , since it was achieved by examination of the test data -LRB- although our examination was rather cursory ; we do 4later experiments using these words as features for machine learning methods did not yield better results .
its estimate of p -LRB- c i d -RRB- takes the following exponential form : for instance , a particular feature \/ class function might fire if and only if the bigram still hate appears and the documents sentiment is hypothesized to be negative .7 importantly , unlike naive bayes , maxent makes no assumptions about the relationships between features , and so might potentially perform better when conditional independence assumptions are not met .
this provides suggestive evidence that sentiment categorization is more difficult than topic classification , which corresponds to the intuitions of the text categorization expert mentioned above .10 nonetheless , we still wanted to investigate
