the prototype strings are drawn from the alphabet a while the observed strings are drawn from the alphabet b. next , we model the joint probability p -LRB- w , xt , yv -RRB- as a product of conditional probabilities , where the joint probability p -LRB- xt , yv | ^ -RRB- of a prototype xt and a string yv is determined by a stochastic transducer ^ , and the conditional probability p -LRB- w | xt , l -RRB- of a class w given a prototype xt is determined from the probabilities p -LRB- w , xt | l -RRB- of the labeled prototypes &lt; w , x t &gt; in the prototype dictionary l. we considered the alternate factorization p -LRB- w , xt , yv | ^ , l -RRB- = p -LRB- yv | xt , ^ -RRB- p -LRB- w , xt | l -RRB- but rejected it as being inconsistent with the main thrust of our paper , which is the automatic acquisition and use of joint probabilities on string pairs .
the transducer parameters are initialized uniformly before training , as are the parameters
recall that our joint probability model p -LRB- w , xt , yv | ^ , l -RRB- is constructed from three separate models : the conditional probability p -LRB- w | xt , l -RRB- is given by the word model p -LRB- w | l -RRB- and the lexical entry model p -LRB- xt | w , l -RRB- , while the joint probability p -LRB- xt , yv | ^ -RRB- is given by the transducer ^ .
