we start by exploring the performance of web counts on two generation tasks for which the use of large data sets has previously shown promising results : -LRB- a -RRB- target language candidate selection for machine translation -LSB- grefenstette 1998 -RSB- and -LRB- b -RRB- context-sensitive spelling correction -LSB- banko and brill 2001a ; 2001b -RSB- .
these include a variety of bayesian classifiers -LSB- golding 1995 ; golding and schabes 1996 -RSB- , decision lists -LSB- golding 1995 -RSB- transformation-based learning -LSB- mangu and brill 1997 -RSB- , latent semantic analysis -LRB- lsa -RRB- -LSB- jones and martin 1997 -RSB- , multiplicative weight update algorithms -LSB- golding and roth 1999 -RSB- , and augmented mixture models -LSB- cucerzan and yarowsky 2002 -RSB- .
subsequent work has used -LRB- v , n1 , p , n2 -RRB- tuples extracted from the penn treebank to train supervised models including a maximum entropy model -LSB- ratnaparkhi et al. 1993 -RSB- , a back-off model -LSB- collins and brooks 1995 -RSB- , transformation-based -LSB- brill and resnik 1994 -RSB- , and memory-based learning -LSB- zavrel et al. 1997 -RSB- .
the training \/ test set therefore contained solely
note that for certain tasks , the performance of a web baseline model might actually be sufficient , so that the effort of constructing a sophisticated supervised model and annotating the necessary training data can be avoided : recall that for three tasks , our web-based models outperformed the best model in the literature -LRB- for mt candidate selection , article generation , and compound interpretation , see table xx -RRB- .
