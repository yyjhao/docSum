the shared task organizers were especially interested in approaches that made use of resources other than the supplied training data , for example gazetteers and unannotated data .
in this section we discuss the sources of the data that were used in this shared task , the preprocessing steps we have performed on the data , the format of the data and the method that was used for evaluating the participating systems .
the split between development data and test data was chosen to avoid systems being tuned to the test data .
this information included gazetteers and unannotated data , and there was one participant who used the output of externally trained named entity recognition systems .
othographic information , affixes , gazetteers and chunk information were also incorporated in most systems although one group reports that the available chunking information did not help -LRB- wu et al. , 2003 -RRB- other features were used less frequently .
one participating team has used externally trained named entity recognition systems for english as a part in a combined system -LRB- florian et al. , 2003 -RRB- .
we
the best performance for both languages has been obtained by a combined learning system that used maximum entropy models , transformation-based learning , hidden markov models as well as robust risk minimization -LRB- florian et al. , 2003 -RRB- .
