evaluation method : each image in the test set is automatically annotated , by taking every region larger than the threshold , quantizing the region to a blob , and using the lexicon to determine the most likely word given that blob ; if the probability of the word given the blob is greater than the relevant threshold , then the image is annotated with that word .
as figure 5 shows , we have some words with very high recall values , and we have some words with low recall .
the effect of retraining : since we can predict only 80 words , we can reduce our vocabulary only to those words , and run em algorithm again .
table 1 and table 2 shows that , with the increasing null threshold values , the number of words decreases
table 3 shows that we have some very nice clusters which have strong semantic or visual relations like kit-horses-mare-foals , leaf-flowers-plants-vegetables or pool-athlete-vines-swimmers and the results are better when we cluster the words -LRB- compare with table 1 -RRB- .
for some good words -LRB- e.g : ocean -RRB- we have up to 70 % correct prediction as shown in figure 7 ; this means that , on this test set , when the word ocean is predicted , 70 % of the time it will be predicted on an ocean region .
