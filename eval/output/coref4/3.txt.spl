two established trec qa evaluation metrics are adopted to assess the results for each run as follows : a confidence-weighted score that rewards systems with high confidence
in our question answering system , piquant , we utilize in parallel multiple answering agents that adopt different processing strategies and consult different knowledge sources in identifying answers to given questions , and we employ resolution mechanisms to combine the results produced by the individual answering agents .
if the two top answers are equivalent , the answer is selected with the combined confidence from both agents ; otherwise , the more confident answer is selected .5 in the second algorithm , the top 5 answers from each agent are allowed to participate in the voting process .
traditional question answering -LRB- qa -RRB- systems typically employ a pipeline approach , consisting roughly of question analysis , document \/ passage retrieval , and answer selection -LRB- see e.g. , -LRB- prager et al. , 2000 ; moldovan et al. , 2000 ; hovy et al. , 2001 ; clarke et al. , 2001 -RRB- -RRB- .
third , passages from agent 2 may contain additional occurrences of the correct answer , which boosts the system s confidence in the answer through the redundancy measure .2 our passage-level combination algorithm adds to the passages extracted by the knowledge-based agent the top - ranked passages from the statistical agent that contain candidate answers of the right type .
