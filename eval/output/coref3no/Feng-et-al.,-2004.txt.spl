it performs 4 times better than a
we believe the crm model makes two assumptions that make it ill-suited for annotations in the image \/ video domain .
let v denote the annotation vocabulary , t denote the training set of annotated images , and let j be an element of t. according to the previous section j is represented as a set of image regions rj = -LCB- r1 ... rn -RCB- along with the corresponding annotation wj e -LCB- 0,1 -RCB- v. we assume that the process that generated j is based on two distinct probability distributions .
given a new -LRB- un-annotated -RRB- image we can split it into regions ra , compute feature vectors 91 ... 9n for each region and then use equation 1 to determine what subset of vocabulary w \* is most likely to co-occur with the set of feature vectors : equation -LRB- 3 -RRB- arises out of placing a gaussian kernel over the feature vector 9i of every region of image j. each kernel is parametrized by the feature covariance matrix e. as a matter of convenience we assumed e = 0 i , where i is the identity matrix .
we tested the algorithms using two different datasets , the corel data set from duygulu et al -LSB- 5 -RSB- and a set of video key frames from nist s video trec -LSB- 12 -RSB- .
