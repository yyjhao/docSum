we define a pcfg-la as a tuple , where a set of observable non-terminal symbols a set of terminal symbols , a set of latent annotation symbols , a set of observable cfg rules , the probability of the occurrence of a complete symbol at a root node , the probability of a rule .
although we omit the details , we can prove the np-hardness by observing that a stochastic tree substitution grammar -LRB- stsg -RRB- can be represented by a pcfg-la model in a similar way to one described by goodman -LRB- 1996a -RRB- , and then using the np-hardness of stsg parsing -LRB- simaan , 2002 -RRB- .
in the first set of experiments , the degree of dependency of trained models on initialization was examined because em-style algorithms yield
the superiority of the third method over the first method seems to stem from the difference in the number of candidate parses from which the outputs are selected .5 the superiority of the third method over the second method is a natural consequence of the consistent use of both in the estimation -LRB- as the objective function -RRB- and in the parsing -LRB- as the score of a parse -RRB- .
our result is lower than the state-of-the-art lexicalized pcfg parsers -LRB- collins , 1999 ; charniak , 1999 -RRB- , but comparable to the unlexicalized pcfg parser of klein and manning -LRB- 2003 -RRB- .
