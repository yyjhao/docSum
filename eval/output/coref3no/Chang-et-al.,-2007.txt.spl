conceptually , although not technically , the most related work to ours is -LRB- shen et al. , 2005 -RRB- that , in a somewhat ad-hoc manner uses soft constraints to guide an unsupervised model that was crafted for mention tracking .
the second problem we consider is extracting fields from advertisements -LRB- grenager et al. , 2005 -RRB- .
we note that in the presence of constraints , the inference procedure -LRB- for finding the output y that maximizes the cost function -RRB- is usually done with search techniques -LRB- rather than viterbi decoding , see -LRB- toutanova et al. , 2005 ; roth and yih , 2005 -RRB- for a discussion -RRB- , we chose beamsearch decoding .
the fact that the constraints are used in the inference procedure -LRB- in particular , for generating new training examples -RRB- allows us to use a learning algorithm that ignores the constraints
figure 3 compares two protocols on the advertisements domain : h &amp; w + i , where we first run the h &amp; w protocol and then apply the constraints during testing stage , and h &amp; w &amp; c + i , which uses constraints to guide the model during learning and uses it also in testing .
first , we claim that defining d -LRB- y , 1c -LRB- , , , -RRB- -RRB- to be the hamming distance is superior to using a binary value , d -LRB- y , 1c -LRB- , , , -RRB- -RRB- = 0 if y e 1c -LRB- , , , -RRB- and 1 otherwise .
