two different ways of generating queries for a given n-gram are employed in the present paper : literal queries use the quoted n-gram directly as a search term for the search engine -LRB- e.g. , the bigram history changes expands to the query '' history changes '' -RRB- .
however , there is also evidence for the reliability of web counts : keller and lapata -LSB- 2003 -RSB- show that the counts generated by two search engines -LRB- google and altavista -RRB- are highly correlated with frequencies obtained from two standard corpora for english -LRB- the bnc and the north american newstext corpus -RRB- .
these models then form the basis for the significance tests reported in table v. -RRB- as explained in section 2.5 , we also test two weakly supervised models that combine web counts and corpus counts using backoff and interpolation .
malouf -LSB- 2000 -RSB- reduces adjective ordering to the well-known problem of estimating n-gram probabilities and proposes a back-off bigram model of adjective pairs for choosing among alternative orders -LRB- p -LRB- -LRB- a , b -RRB- | -LCB- a , b -RCB- -RRB- vs. p -LRB- -LRB- b , a -RRB- | -LCB- a , b -RCB- -RRB- -RRB- .
the first analysis task
frequencies for the two models were obtained from the same corpus and from rogets thesaurus -LRB- version 1911 -RRB- by counting pairs of nouns that are either strictly adjacent or co-occur within a window of a fixed size -LRB- e.g. , two , three , fifty , or hundred words -RRB- .
