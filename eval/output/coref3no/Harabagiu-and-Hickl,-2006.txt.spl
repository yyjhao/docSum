we expect that the meaning of an information-seeking scenario s can be represented as a question under discussion -LRB- qud -RRB- qs , which denotes a partially-ordered set of subquestions -LRB- q e qs -RRB- that represent the entire set of questions that could potentially be asked in order to er information relevant to s. taken together , we expect these subquestions to represent the
in case 2 , the users question is entailed by the scenario , but no corresponding entailment relationship can be established between the scenario and the answer passage identified by the q \/ a system as an answer to the question .
this architecture includes three basic types of modules : -LRB- 1 -RRB- a context discovery module , which identifies passages relevant to the concepts mentioned in a scenario , -LRB- 2 -RRB- a textual entailment module , which recognizes implicational relationships between passages , and -LRB- 3 -RRB- a entailment merging module , which ranks relevant passages according to their relevance to the scenario itself .
annotators were tasked with evaluating three types of output from our q \/ a system : -LRB- 1 -RRB- the ranked list of passages retrieved by our systems passage retrieval module , -LRB- 2 -RRB- the list of passages identified as being ce by the scenario , and -LRB- 3 -RRB- the set of answers marked as being ce by the scenario -LRB- ansset3 -RRB- .
