in recent years , the literature includes compelling evaluation results for several natural language parsers that train and test on the u. penn treebank -LRB- marcus et al. , 1993 -RRB- , including the work of magerman -LRB- 1995 -RRB- , collins -LRB- 1999 -RRB- , collins &amp; duffy -LRB- 2002 -RRB- , charniak -LRB- 2000 -RRB- , and klein &amp; manning -LRB- 2003 -RRB- .
since the publication of the treebank , published evaluations of non-treebank parsers -LRB- i.e. , parsers not designed with the conventions of the english language u. penn treebank in mind -RRB- are rarely encountered ; recent exceptions include an evaluation of the xerox lfg f - structure parser -LRB- riezler , 2002 -RRB- and the
our conjecture is that if we focus on maximal projections of heads -LRB- mph -RRB- , we are likely to find much broader agreement than if we try to evaluate based on order of attachment or on the granularity of intermediate projections .
in particular , to address tokenization issues , we added a post-process to nlpwin to tokenize in the manner of the treebank , and we exclude part-of-speech tags and constituent labels from our evaluation .
a challenge posed by focusing on maximal projections of heads is the absence of annotations of heads and head inheritance in the treebank itself .1 to rectify this , we will employ a set of head-labeling rules and compute maximal projections of heads for the reference or gold treebank trees .
