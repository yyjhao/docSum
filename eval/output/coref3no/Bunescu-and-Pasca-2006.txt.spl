one of the challenges in creating such an alternative search result page is the inherent ambiguity of the queries , as several instances of the same class -LRB- e.g. , different people -RRB- or different classes -LRB- e.g. , a type of snake , a programming language , or a movie -RRB- may share the same name in the query .
the aim of this formulation is to find a weight vector w such that 1 -RRB- the number of ranking constraints w -LRB- d -LRB- q , q.e -RRB- &gt; w -LRB- d -LRB- q , ek -RRB- from the training data that are violated is minimized , and 2 -RRB- the ranking function w -LRB- d -LRB- q , ek -RRB- generalizes well beyond the training data .
it is straightforward to show that the dot product between two feature vectors -LRB- d -LRB- q , ek -RRB- and -LRB- d -LRB- q , e -RRB- is equal with the product between the number of common words in the contexts of the two queries and the number of categories common to the two named entities , plus the product of the two
as can be seen in the last two columns , the taxonomy kernel significantly outperforms the cosine similarity in the first three scenarios , confirming our intuition that correlations between words from the query context and categories from wikipedia taxonomy provide useful information for disambiguating named entities .
