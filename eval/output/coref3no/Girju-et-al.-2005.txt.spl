the annotation of each example consists of specifying its feature vector and the most appropriate interpretation based on : -LRB- 1 -RRB- the list of 35 semantic relations -LRB- 35 srs -RRB- -LRB- table 3 -RRB- and -LRB- 2 -RRB- the lauer 's list of 8 prepositional paraphrases -LRB- 8 pps -RRB- -LRB- cf .
since we wanted to compare our approach with two state-of-the-art unsupervised probabilistic models , we selected as test sets those randomly obtained by lauer from grolier encyclopedia for each type of noun compounds : 282 nounnoun pairs for two noun compounds , and 244 three noun instances for three noun compounds .
we use two different lists of semantic target categories : the list
since we wanted to measure the impact of syntactic and semantic ambiguities of noun compounds on the interpretation performance , we further tested the probabilistic web-based model on four distinct test sets selected from the wall street journal text collection , each containing 200 nounnoun pairs encoding different types of ambiguity : in set # 1 the noun constituents had only one part of speech and one wordnet sense ; in set # 2 the nouns had at least two possible parts of speech and were semantically unambiguous , in set # 3 the nouns were ambiguous only semantically , and in set # 4 they were ambiguous both syntactically and semantically .
