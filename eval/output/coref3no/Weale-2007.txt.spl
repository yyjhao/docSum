we outline our algorithm in section 3 before introducing our data set and evaluating our algorithms performance in section 4 .
additionally , they observe that since their algorithm is language independent , additional languages can be added by simply running their algorithm over the appropriate wikipedia language set .
in their 2006 paper , they demonstrate a system for text categorization and use wikipedia to overcome the bottleneck generated by limitations of the open directory project .
therefore , the first step in our algorithm is to extract entities from the documents .
in our evaluation , we decided to try two different types of classifiers : support vector machines and decision trees .
for our evaluation , we utilize the svmlight classifier3 and the c4 .5 decision tree algorithm .
in this paper , we have introduced a method for document categorization using wikipedia as a large - scale knowledge base for information about named entities .
in our current system , we discard entities that need
our toy corpus was used to demonstrate the initial concept , but we need to see how this might work in a more general classification context .
to this end , we have obtained the rcv 1 corpus , and will be running experiments to see how our algorithm works on this corpus .
