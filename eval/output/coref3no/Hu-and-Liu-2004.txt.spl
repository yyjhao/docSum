given a set of customer reviews of a particular product , the task involves three subtasks : -LRB- 1 -RRB- identifying features of the product that customers have expressed their opinions on -LRB- called product features -RRB- ; -LRB- 2 -RRB- for each feature , identifying review sentences that give positive or negative opinions ; and -LRB- 3 -RRB- producing a summary using the discovered information .
the system performs the summarization in three main steps -LRB- as discussed before -RRB- : -LRB- 1 -RRB- mining product features that have been commented on by customers ; -LRB- 2 -RRB- identifying opinion sentences in each review and deciding whether each opinion sentence is positive or negative ; -LRB- 3 -RRB- summarizing the results .
if a feature has a p-support lower than the minimum p - support -LRB- in our system , we set it to 3 -RRB- and
to have a reasonably broad range of adjectives , we first manually come up a set of very common adjectives -LRB- in our experiment , we used 30 -RRB- as the seed list , e.g. positive adjectives : great , fantastic , nice , cool and negative adjectives : bad , dull .
while human taggers do not regard these sentences as opinion sentences as there is no indication of whether the user likes the features or not , our system labels these sentences as opinion sentences because they contain both product features and some opinion adjectives .
