a growing number of statistical classification methods and machine learning techniques have been applied to text categorization in recent years , including multivariate regression models -LSB- 8 , 27 -RSB- , nearest neighbor classification -LSB- 4 , 23 -RSB- , bayes probabilistic approaches -LSB- 20 , 13 -RSB- , decision trees -LSB- 13 -RSB- , neural networks -LSB- 21 -RSB- , symbolic rule learning -LSB- 1 , 16 , 3 -RSB- and inductive learning algorithms -LSB- 3 , 12 -RSB- .
these criteria are : document frequency -LRB- df -RRB- , information gain -LRB- ig -RRB- , mutual information -LRB- mi -RRB- , a xz statistic -LRB- chi -RRB- , and term strength -LRB- ts -RRB- .
we computed the document frequency for each unique term in the training corpus and removed from the
we computed for each category the x2 statistic between each unique term in a training corpus and that category , and then combined the category - specific scores of each term into two scores : the computation of chi scores has a quadratic complexity , similar to mi and ig .
this allows a straight-forward global evaluation of per document categorization performance , i.e. , measuring the goodness of category ranking given a document , rather than per category performance as is standard when applying binary classifiers to the problem .
4.3 primary results figure 1 displays the performance curves for knn on reuters -LRB- 9,610 training documents , and 3,662 test documents -RRB- after term selection using ig , df , ts , mi and chi thresholding , respectively .
