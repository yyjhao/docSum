figure 1 shows the relationship between the amount of parallel arabic-english training data used and both the translation quality of a state-of - the-art phrase-based smt system and the time required to perform the training with the widely-used moses toolkit on a commodity server .1 building a model using 5m sentence pairs -LRB- the amount of arabic-english parallel text publicly available from the ldc -RRB- takes just over two days .2 this represents an unfortunate state of affairs for the research community : excessively long turnaround on
assuming a given sentence length m for f ' 1 , the translation probability is defined as follows : in this section , we consider the mapreduce implementation of two specific alignment models : estimating the parameters for these models is more difficult -LRB- and more computationally expensive -RRB- than with the models considered in the previous section : rather than simply being able to count the word pairs and alignment relationships and estimate the models directly , we must use an existing model to compute the expected counts for all possible alignments , and then use these counts to update the new model .7 this training strategy is referred to as expectation - maximization -LRB- em -RRB- and is guaranteed to always improve the quality of the prior model at each iteration -LRB- brown et al. , 1993 ; dempster et al. , 1977 -RRB- .
