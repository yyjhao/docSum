we do not directly address here the problems of applying preference functions to select the best analysis when none is completely correct ; we assume , based on our experience with the spoken language translator , that functions and scaling factors trained on cases where a completely correct analysis exists will also perform fairly well on
as mentioned earlier , the preference score is a weighted sum of a set of preference functions : each preference function fb takes a complete qlf representation qi as input , returning a numerical score sib , the overall preference score being computed by summing over the product of function scores with their associated scaling factors cb .
from these five functions on triples we define five semantic collocation preference functions applied to qlfs , in each case by averaging over the result of applying the function to each triple derived from a qlf .
however , the difference between the chi and chi-squared functions is no longer quite so clear cut , and the relative advantage of the mean distance function compared with the chi function is less , perhaps because other preference functions make up for some shortfall of the chi function that is , at least in part , taken account of by the mean distance function .
