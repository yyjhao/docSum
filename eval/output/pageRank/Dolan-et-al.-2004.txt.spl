we show that although the edit distance corpus is well-suited as training data for the alignment algorithms currently used in smt , it is an incomplete source of information about paraphrase relations , which exhibit many of the characteristics of comparable bilingual corpora or free translations .
we held out a set of news clusters from our training data and randomly
the f2 training data is probably too sparse and , with 40 % unrelated sentence pairs , too noisy to achieve equally good results ; nevertheless the gap between the results for the two training data types is dramatically narrower on the f2 test data .
the nearly comparable numbers for the two training data sets , at 13.2 % and 14.7 % respectively , suggest that the l12 training corpus provides no substantive advantage over the f2 data when tested on the more complex test data .
the most common paraphrase alternations that we observed fell into the following broad categories : elaboration : sentence pairs can differ in total information content , with an added word , phrase or clause in one sentence that has no counterpart in the other -LRB- e.g. the nasdaq \/ the tech-heavy nasdaq -RRB- .
after summing all alternations in each sentence pair , we calculated the average number of occurrences of each paraphrase type in each data set .
