based on a series of experiments over the past two years -LSB- 5,6 -RSB- we have developed the following procedure for acquiring semantic
co-occurrence smoothing is a method which has been recently proposed for smoothing n-gram models -LSB- 3 -RSB- .3 the core of this method involves the computation of a co-occurrence matrix -LRB- a matrix of confusion probabilities -RRB- pc -LRB- wilivi -RRB- , which indicates the probability of word wi occurring in contexts in which word wi occurs , averaged over these contexts .
the test corpus used to generate the triples which were manually classified ' consisted of i -LRB- -RRB- articles , also from the wall street journal , distinct , front those in the training set .
we began by generating triples from the entire corpus and evaluating the selectional patterns as described above ; the resulting recall \/ precision curve generated by varying the threshold is shown in figure 1 .
to see how pattern coverage improves with corpus size , we divided our training corpus into 8 segments and computed sets of triples based on the first segment , the first two segments , etc .
we have also demonstrated that for a given corpus size coverage can be significantly improved by using the corpus to identify selectionally related terms , and using these similarities to generalize the patterns observed in the training corpus .
