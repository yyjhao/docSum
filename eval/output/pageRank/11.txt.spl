in the following four sections , we describe the changes we have made to our system for this year : question classification -LRB- section 3 -RRB- , storing data with multi-dimensional markup -LRB- section 4 -RRB- , and probabilistic answer processing -LRB- sections 5 and 6 -RRB- .
we therefore decided on using three different types of question classes : a table type that linked the question to an available table column -LRB- 17 classes -RRB- , a coarse-grained type that linked the question to the types recognized by our named-entity recognizer -LRB- 7 classes -RRB- , and a fine-grained type that linked the question to wordnet synsets -LRB- 166 classes -RRB- .
in order to make it possible for our answer re-ranking module -LRB- described in section 6 -RRB- to rank answers from different streams , we took advantage of answer patterns from previous editions of clef qa to estimate the probability that an answer from a given stream with a given confidence score is correct .
for answers to other questions , we use the same ratio for ill-formed answers as we do for ill-typed answers -LRB- 0.34 -RRB- , but we do not compute any update for well-formed answers -LRB- i.e. , we update
for answers to questions with the following answer types only the very basic well-formedness checks noted are additionally performed : for questions expecting named entities , dates , or numeric answers , more significant wellformedness and well-typedness checks are performed .
