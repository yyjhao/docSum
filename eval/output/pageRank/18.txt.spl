for each classification problem , we identify the feature set size which optimizes the efficiency , that is , optimizes the rate at which classification performance under active
as mentioned in section 2.2 the difference between systems 3 and 4 is in that feature selection precedes active learning in the former , and the best feature subset is picked in a retrospective manner , while it follows active learning in the latter .
we then move on to discuss a real system which employs a two-tiered approach of document feedback and feature feedback like the system in figure 2 which we evaluate using a simulation : we obtain feedback on features and documents apriori , and use the judgments so obtained to measure the effectiveness of our approach .
our work is related to a number of areas including query learning , active learning , use of -LRB- prior -RRB- knowledge and feature selection in machine learning , term-relevance feedback in information retrieval , and human-computer interaction .
budgeted learning also works on identifying the predictive features during an active learning setting , but in this case the feature values are unknown and there is a cost to finding each feature s value for each instance of interest -LRB- such as the outcome of blood test on an individual -RRB- -LRB- lizotte et al. , 2003 -RRB- .
