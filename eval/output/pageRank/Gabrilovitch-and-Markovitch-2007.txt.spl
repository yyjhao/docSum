however , prior work on semantic relatedness was based on purely statistical techniques that did not make use of background knowledge -LSB- baeza-yates and ribeiro-neto , 1999 ; deerwester et al. , 1990 -RSB- , or on lexical resources that incorporate very limited knowledge about the world -LSB- budanitsky and hirst , 2006 ; jarmasz , 2003 -RSB- .
we implemented the semantic interpreter as a centroidbased classifier -LSB- han and karypis , 2000 -RSB- , which , given a text fragment , ranks all
we processed the text of these articles by removing stop words and rare words , and stemming the remaining words ; this yielded 389,202 distinct terms , which served for representing wikipedia concepts as attribute vectors .
to assess word relatedness , we use the wordsimilarity-353 collection2 -LSB- finkelstein et al. , 2002 -RSB- , which contains 353 word pairs .3 each pair has 13 16 human judgements , which were averaged for each pair to produce a single relatedness score .
prior work in the field pursued three main directions : comparing text fragments as bags of words in vector space -LSB- baeza-yates and ribeiro-neto , 1999 -RSB- , using lexical resources , and using latent semantic analysis -LRB- lsa -RRB- -LSB- deer - wester et al. , 1990 -RSB- .
prior work in the field mostly focused on semantic similarity of words , using r &amp; g -LSB- rubenstein and goodenough , 1965 -RSB- list of 65 word pairs and m &amp; c -LSB- miller and charles , 1991 -RSB- list of 30 word pairs .
