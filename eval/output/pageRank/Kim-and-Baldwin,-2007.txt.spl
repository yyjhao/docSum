our approach to the task was to : -LRB- 1 -RRB- naively treat all nominal pairs as ncs -LRB- e.g. the climate in the forest is treated as an instance of climate forest -RRB- ; and -LRB- 2 -RRB- translate the individual binary classification tasks into a single multiclass classification task , in the interests of benchmarking existing sr interpretation methods over a common dataset .
for the sense collocation method , we experiment with a substitution method whereby we replace one constituent in a training nc instance by a similar word , and annotate the new instance with the same sr as the original nc .
since the sense collocations in the expanded training data have been varied through the advent of hypernyms and sister words , the number of sense collocations in the
fourth , we apply the constituent similarity co - training method over the consolidated training data -LRB- from both sense collocation and constituent similarity co-training -RRB- with the threshold unchanged at 0.8 .
4.2 architecture -LRB- ii -RRB- we perform iterative co-training as described in section 3.2 , with the slight variation that we hold off reducing the threshold if more than 10 % of the test instances are tagged on a given iteration , giving other test instances a chance to be tagged at a higher threshold level relative to newly generated training instances .
