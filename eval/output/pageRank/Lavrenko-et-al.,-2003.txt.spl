our model computes a joint probability of image features over different regions in an image using a training set and uses this joint probability to annotate and retrieve images .
more formally , we propose a statistical generative model to automatically learn the semantics of images - that is , for annotating and retrieving images based on a training set of images .
given a training set of images with annotations , we show that probabilistic models allow us to predict the probability of generating a word given the features computed over different regions in an image .
it
their translation model applies one of the classical statistical machine translation models to translate from the set of keywords of an image to the set of blobs forming the image .
image pixels are produced by first picking a set of i.i.d. feature vectors , then generating image regions from the feature vectors , and finally stacking the regions on top of each other .
we divided the dataset into 3 parts - with 4,000 training set images , 500 evaluation set images and 500 images in the test set .
we compare the annotation performance of the four models : the co-occurrence model -LSB- 9 -RSB- , the translation model -LSB- 4 -RSB- , cmrm -LSB- 5 -RSB- and the model proposed in this paper -LRB- crm -RRB- .
