the prototype strings are drawn from the alphabet a while the observed strings are drawn from the alphabet b. next , we model the joint probability p -LRB- w , xt , yv -RRB- as a product of conditional probabilities , where the joint probability p -LRB- xt , yv | ^ -RRB- of a prototype xt and a string yv is determined by a stochastic transducer ^ , and the conditional probability p -LRB- w | xt , l -RRB- of a class w given a prototype xt is determined from the probabilities p -LRB- w , xt | l -RRB- of the labeled prototypes &lt; w , x t &gt; in the prototype dictionary l. we considered the alternate factorization p -LRB- w , xt , yv | ^ , l -RRB- = p -LRB- yv | xt , ^ -RRB- p -LRB- w , xt | l -RRB- but rejected it as being inconsistent with the main thrust of our paper , which is the automatic acquisition and use of joint probabilities on string pairs .
the transducer parameters are initialized uniformly before training , as are the parameters of the word model p -LRB- w | l -RRB- and the conditional lexicon model p -LRB- xt | w , l -RRB- for all entries &lt; w , xt &gt; in l. note that a uniform p -LRB- w | l -RRB- and a uniform p -LRB- xt | w , l -RRB- are not equivalent to a uniform p -LRB- w , xt | l -RRB- because more frequent words tend to have more
