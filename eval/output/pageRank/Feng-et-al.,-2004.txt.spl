we then learn a joint probability model for -LRB- continuous -RRB- image features and words called a relevance model and use this model to annotate test images which we have not seen .
this model simultaneously learns the joint probabilities of associating words with image features using a training set of images with keywords and then generates multiple probabilistic annotations for each image .
let v denote the annotation vocabulary , t denote the training set of annotated images , and let j be an element of t. according to the previous section j is represented as a set of image regions rj = -LCB- r1 ... rn -RCB- along with the corresponding annotation wj e -LCB- 0,1 -RCB- v. we assume that the process that generated j is based
given a new -LRB- un-annotated -RRB- image we can split it into regions ra , compute feature vectors 91 ... 9n for each region and then use equation 1 to determine what subset of vocabulary w \* is most likely to co-occur with the set of feature vectors : equation -LRB- 3 -RRB- arises out of placing a gaussian kernel over the feature vector 9i of every region of image j. each kernel is parametrized by the feature covariance matrix e. as a matter of convenience we assumed e = 0 i , where i is the identity matrix .
