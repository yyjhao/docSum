we describe latent dirichlet allocation ( lda ) , a generative probabilistic model for collections of discrete data such as text corpora .
lda is a three-level hierarchical bayesian model , in which each item of a collection is modeled as a finite mixture over an underlying set of topics .
each topic is , in turn , modeled as an infinite mixture over an underlying set of topic probabilities .
in the context of text modeling , the topic probabilities provide an explicit representation of a document .
we present efficient approximate inference techniques based on variational methods and an em algorithm for empirical bayes parameter estimation .
we report results in document modeling , text classification , and collaborative filtering , comparing to a mixture of unigrams model and the probabilistic lsi model .
