we propose an approach to learning the semantics of images which allows us to automatically annotate an image with keywords and to retrieve images based on text queries .
we do this using a formalism that models the generation of annotated images .
we assume that every image is divided into regions , each described by a continuous-valued feature vector .
given a training set of images with annotations , we compute a joint probabilistic model of image features and words which allow us to predict the probability of generating a word given the image regions .
this may be used to automatically annotate and retrieve images given a word as a query .
experiments show that our model significantly outperforms the best of the previously reported results on the tasks of automatic image annotation and retrieval .
