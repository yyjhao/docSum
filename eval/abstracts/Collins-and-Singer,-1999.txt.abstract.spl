this paper discusses the use of unlabeled examples for the problem of named entity classification .
a large number of rules is needed for coverage of the domain , suggesting that a fairly large number of labeled examples should be required to train a classifier .
however , we show that the use of unlabeled data can reduce the requirements for supervision to just 7 simple " seed " rules .
the approach gains leverage from natural redundancy in the data : for many named-entity instances both the spelling of the name and the context in which it appears are sufficient to determine its type .
we present two algorithms .
the first method uses a similar algorithm to that of ( yarowsky 95 ) , with modifications motivated by ( blum and mitchell 98 ) .
the second algorithm extends ideas from boosting algorithms , designed for supervised learning tasks , to the framework suggested by ( blum and mitchell 98 ) .
