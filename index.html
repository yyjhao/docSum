<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>CS2309 Project Presentation</title>
		<base target="_blank">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/default.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
		<style>
			.reveal pre:not(.small-code){
				font-size: 1.2em;
				line-height: 1;
			}

			.reveal .slide-background .present{
				opacity: 0.2;
			}

			.reveal code{
				color: darkgreen;
			}

			.reveal pre code{
				color: #eee;
			}

			.reveal strong{
				color: brown;
			}

			.reveal .huge{
				font-size: 1.5em;
				line-height: 1.2;
				height: auto;
				color: brown;
			}

			.reveal .dark-back h2{
				color: white;
			}

			.reveal .dark-back h1{
				color: white;
				text-transform: none;
			}

			.two-col{
				margin: 0;
				padding: 0;
			}

			.two-col li{
				width: 50%;
				float: left;
				margin: 0;
				padding: 0;
				list-style: none;
				text-align: center;
			}

			.reveal h4{
				font-size: 0.7em;
				font-style: normal;
				font-family: inherit;
				text-transform: none;
			}
		</style>
		<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
		<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
	</head>

	<body>
		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section data-markdown data-background="images/info.jpg" class="dark-back">
					# SenRank
					## A novel automatic summarisation algorithm
				</section>
				<section>
					<section data-markdown data-background="images/Infomation-Overload.jpg" data-background-position="130% 130%" data-background-size="60%">
						## Motivation

						1. Explosive number of documents online
						1. Necessitates a fast way to filter the information
						1. Automatic summarisation aids readers in such processes

					</section>
					<section>
						<h2>
							Examples
						</h2>
						<ol class="two-col">
							<li>
								<div>Search Engine Previews</div>
								<img src="images/search-engine.png" />
							</li>
							<li>
								<div>Automatic highlights</div>
								<img src="images/Highlight.jpg" />
							</li>

						</ol>
					</section>
				</section>
				<section>
					<section data-markdown>
						## Fomulation

						* Assumption
							1. Articles consist of ideas
							1. Ideas flow
							1. Each sentence presents some ideas
							1. Ideas are expressed through words
							1. Overlap of words signifies relation of ideas
							1. Thus relation of sentences
					</section>
					<section data-markdown>
						## Fomulation

						* A sentence is *summarising* if ideas from many other sentences flow to it
						* A set of sentences with such characteristics can be a summary
							* Note that overlapping of ideas in sentences within such a set should be minimized to achieve a _succinct_ summary.
					</section>
					<section data-markdown>
						## Fomulation

						* An article is a graph of sentences
						* Two sentences are connected if they are related
							* A sentence is more likely to flow to another if the edge has a higher weight.
							* The weight of the edge is proportional to their relation
						* Compute how likely it is to flow to a certain sentence
						* Aggregate the top few (non-overlapping) sentences as summary

					</section>
				</section>

				<section>
					<section data-markdown>
						## Solution

						1. The relation of two sentence, therefore the weight of edge connecting them
							* = number of word overlaps
								* Not all words can be counted
							* plus number of shared references in both sentences
						1. The edges are bi-directional
					</section>
					<section data-markdown>
						## Solution

						1. Simulate a random walk on such a graph
							* With PageRank&trade;
						1. Rank the sentences with their PageRank&trade; score
						1. Pick the top sentences that do not overlap too much
					</section>
				</section>
				<section>
					<section data-markdown>
						## Algorithm
						#### **Tokenize** &rarr; Compute Co-reference &rarr; Parse Co-reference &rarr; Count Overlap &rarr; Build Adjacency Matrix &rarr; Run PageRank &rarr; Generate Summary

						-----
						
						* We use Stanford Corenlp to tokenize articles
					</section>
					<section data-markdown>
						## Algorithm
						#### Tokenize &rarr; **Compute Co-reference** &rarr; Parse Co-reference &rarr; Count Overlap &rarr; Build Adjacency Matrix &rarr; Run PageRank &rarr; Generate Summary

						-----
						
						* We use Stanford Corenlp to compute co-references
					</section>
					<section data-markdown>
						## Algorithm
						#### Tokenize &rarr; Compute Co-reference &rarr; **Parse Co-reference** &rarr; Count Overlap &rarr; Build Adjacency Matrix &rarr; Run PageRank &rarr; Generate Summary

						-----
						
						* The co-reference data is a list of tuples $(c_1, c_2,...,c_n)$
							* Note that there can be some $i, j$ such that $i \neq j$ and $c_i = c_j$ in some tuples
						* Using the co-reference information, we build an adjacency Matrix $$A_{ij} = a_i + a_j$$
							* where
								* $k$ is some constant
								* $a_i$ is the number of times $i$th sentence appearing in tuples that contains $j$th sentences
								* Conversely for $a_j$
					</section>
					<section>
						<h2>Algorithm</h2>
						<h4>
							Tokenize &rarr; Compute Co-reference &rarr; Parse Co-reference &rarr; <strong>Count Overlap</strong> &rarr; Build Adjacency Matrix &rarr; Run PageRank &rarr; Generate Summary
						</h4>

						<hr />
						
						<ul>
							<li> Build another adjacency Matrix
								$$B_{ij} = \sum\limits_{w \in W} w_iw_j$$
								where $W$ is the set of words we consider for overlapping and $w_i$ is the number of times Word $w$ appears in sentence $i$
							</li>
						</ul>
					</section>
					<section>
						<h2>Algorithm</h2>
						<h4>
							Tokenize &rarr; Compute Co-reference &rarr; Parse Co-reference &rarr; Count Overlap &rarr; <strong>Build Adjacency Matrix</strong> &rarr; Run PageRank &rarr; Generate Summary
						</h4>

						<hr />
						
						<ul>
							<li> 
								The final adjancency Matrix is

								$$ C = k_aA + k_bB $$

								where $k_a, k_b$ are some constants
							</li>
						</ul>
					</section>
					<section>
						<h2>Algorithm</h2>
						<h4>
							Tokenize &rarr; Compute Co-reference &rarr; Parse Co-reference &rarr; Count Overlap &rarr; Build Adjacency Matrix &rarr; <strong>Run PageRank</strong> &rarr; Generate Summary
						</h4>

						<hr />
						
						<ul>
							<li> 
								We run PageRank on $C$ to obtain a PageRank score for all sentences
							</li>
						</ul>
					</section>
					<section>
						<h2>Algorithm</h2>
						<h4>
							Tokenize &rarr; Compute Co-reference &rarr; Parse Co-reference &rarr; Count Overlap &rarr; Build Adjacency Matrix &rarr; Run PageRank &rarr; <strong>Generate Summary</strong>
						</h4>

						<hr />
						
						<ol>
							<li> 
								$S$ is the set of all sentences
							</li>
							<li>
								$R$ is the set of sentences in the summary
							<li>
								Loop while $S \neq \emptyset$
								<ol>
									<li>Pick $s \in S$ such that s has a highest score</li>
									<li>$R = R \cup \{s\}$</li>
									<li>Let $T = \{\text{sentence } i \mid C_{si} > m\}$</li>
									<li>$S = S - T$</li>
									<li>If $R$ exceeds the word limit, trancate the last sentence added to match the word limit</li>
									<li>If $R$ is matches the word limit, terminate the loop</li>
								</ol>
							</li>
							<li>
								Output sentences in $R$ according to their original order in $S$
							</li>
						</ol>
					</section>
					<section data-markdown>
						## Example
					</section>
				</section>
				<section>
					<section data-markdown>
						## Experiment Setup

						* We use 178 papers in _Scholarly Paper Recommendation Dataset_ from WING, NUS
						* The abstracts are used as model summaries and the contents are used as input
						* We use ROUGE to evaluate the quality of our summaries based on the abstracts
						* For our experiment, we use the R-score from ROGUE since the model summaries do not have a word limit
						* For our algorithms, the word limit is set to $200$
						* $m$ used in removing overlapping sentence is set to $20$
					</section>
					<section data-markdown>
						## Algorithms
						
						### $$ C = k_aA + k_bB $$

						* Random: randomly pick sentences from content
						* Degree: $k_a = 0$ (do not consider co-reference), and do not run PageRank, just rank by the degrees
						* PageRank: $k_a = 0$ (do not consider co-reference)
						* Coref_equal: $k_a = 1, k_b = 1$
						* Coref_twice: $k_a = 2, k_b = 1$
						* Coref_large: $k_a = 5, k_b = 1$
						* Coref_only: $k_a = 1, k_b = 0$ (only consider co-reference)
					</section>
					<section data-markdown>
						## Results

						..mean table here..
					</section>
					<section data-markdown>
						## Comparison

						* Random &lt; Degree
					</section>
				</section>
				<section>
					<section data-markdown>
						## Conclusion
					</section>
				</section>
				<section data-markdown>
					# Q ? A : done();
				</section>
			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: "beige", // available themes are in /css/theme
				transition: "linear", // default/cube/page/concave/zoom/linear/fade/none

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});

			var ticker = 0;
			function retick(){
				clearInterval(ticker);
				ticker = setInterval(function(){
					Reveal.next();
				}, 49000);
			}

			// retick();
			// Reveal.addEventListener('slidechanged', retick);

		</script>

	</body>
</html>
