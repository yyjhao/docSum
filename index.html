<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>CS2309 Project Presentation</title>
		<base target="_blank">

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/default.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
		<style>
			.reveal pre:not(.small-code){
				font-size: 1.2em;
				line-height: 1;
			}

			.reveal .slide-background .present{
				opacity: 0.2;
			}

			.reveal code{
				color: darkgreen;
			}

			.reveal pre code{
				color: #eee;
			}

			.reveal strong{
				color: brown;
			}

			.reveal .huge{
				font-size: 1.5em;
				line-height: 1.2;
				height: auto;
				color: brown;
			}

			.reveal .small{
				font-size: 0.5em;
				line-height: 1;
			}

			.reveal .dark-back h2{
				color: white;
			}

			.reveal .dark-back h1{
				color: white;
				text-transform: none;
			}

			.two-col{
				margin: 0;
				padding: 0;
				height: 100%;
			}

			.two-col li{
				width: 50%;
				float: left;
				margin: 0;
				padding: 0;
				list-style: none;
				text-align: center;
				overflow-y: auto;
				height: 100%;
			}

			.reveal h4{
				font-size: 0.7em;
				font-style: normal;
				font-family: inherit;
				text-transform: none;
			}

			.reveal table{
				border-collapse: collapse;
				border: 1px solid black;
				margin: 0 auto;
			}

			.reveal td, .reveal th{
				border: 1px solid black;
				padding: 15px;
				font-size: 0.7em;
			}

			.reveal th{
				font-weight: bold;
			}

			.reveal .justify{
				text-align: justify;
				padding: 10px;
				box-sizing: border-box;
			}

			.reveal .justify h3{
				text-align: center;
			}
		</style>
		<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
		<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
	</head>

	<body>
		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section data-markdown data-background="images/info.jpg" class="dark-back">
					# SenRank
					## A novel automatic summarisation algorithm
				</section>
				<section>
					<section data-markdown data-background="images/Infomation-Overload.jpg" data-background-position="130% 130%" data-background-size="60%">
						## Motivation

						1. Explosive number of documents online
						1. Necessitates a fast way to filter the information
						1. Automatic summarisation aids readers in such processes

					</section>
					<section>
						<h2>
							Examples
						</h2>
						<ol class="two-col">
							<li>
								<div>Search Engine Previews</div>
								<img src="images/search-engine.png" />
							</li>
							<li>
								<div>Automatic highlights</div>
								<img src="images/Highlight.jpg" />
							</li>

						</ol>
					</section>
				</section>
				<section>
					<section data-markdown>
						## Fomulation

						* Assumption
							1. Articles consist of ideas
							1. Ideas flow
							1. Each sentence presents some ideas
							1. Ideas are expressed through words
							1. Overlap of words signifies relation of ideas
							1. Thus relation of sentences
					</section>
					<section data-markdown>
						## Fomulation

						* A sentence is *summarising* if ideas from many other sentences flow to it
						* A set of sentences with such characteristics can be a summary
							* Note that overlapping of ideas in sentences within such a set should be minimized to achieve a _succinct_ summary.
					</section>
					<section data-markdown>
						## Fomulation

						* An article is a graph of sentences
						* Two sentences are connected if they are related
							* A sentence is more likely to flow to another if the edge has a higher weight.
							* The weight of the edge is proportional to their relation
						* Compute how likely it is to flow to a certain sentence
						* Aggregate the top few (non-overlapping) sentences as summary

					</section>
				</section>

				<section>
					<section data-markdown>
						## Solution

						1. The relation of two sentence, therefore the weight of edge connecting them
							* = number of word overlaps
								* Not all words can be counted
							* plus number of shared references in both sentences
						1. The edges are bi-directional
					</section>
					<section data-markdown>
						## Solution

						1. Simulate a random walk on such a graph
							* With PageRank&trade;
						1. Rank the sentences with their PageRank&trade; score
						1. Pick the top sentences that do not overlap too much
					</section>
				</section>
				<section>
					<section data-markdown>
						## Algorithm
						#### **Tokenize** &rarr; Compute Co-reference &rarr; Parse Co-reference &rarr; Count Overlap &rarr; Build Adjacency Matrix &rarr; Run PageRank &rarr; Generate Summary

						-----
						
						* We use Stanford Corenlp to tokenize articles
					</section>
					<section data-markdown>
						## Algorithm
						#### Tokenize &rarr; **Compute Co-reference** &rarr; Parse Co-reference &rarr; Count Overlap &rarr; Build Adjacency Matrix &rarr; Run PageRank &rarr; Generate Summary

						-----
						
						* We use Stanford Corenlp to compute co-references
					</section>
					<section>
						<h2>Algorithm</h2>
						<h4>Tokenize &rarr; Compute Co-reference &rarr; <strong>Parse Co-reference</strong> &rarr; Count Overlap &rarr; Build Adjacency Matrix &rarr; Run PageRank &rarr; Generate Summary</h4>

						<hr />
						<ul>
							<li> The co-reference data is a list of tuples $(c_1, c_2,...,c_n)$
								<ul>
									<li> Note that there can be some $i, j$ such that $i \neq j$ and $c_i = c_j$ in some tuples
									</li>
								</ul>
							</li>
							<li> Using the co-reference information, we build an adjacency Matrix $$A_{ij} = a_{ij} + a_{ji}$$
								<ul>
									<li> where
										<ul>
											<li> $a_{ij}$ is the number of times $i$th sentence appearing in tuples that contains $j$th sentences
											</li>
											<li> If we have (1, 1, 2, 3) and (1, 3), then $a_{12} = 2$ and $a_{13} = 3$
											</li>
										</ul>
									</li>
								</ul>
							</li>
						</ul>
					</section>
					<section>
						<h2>Algorithm</h2>
						<h4>
							Tokenize &rarr; Compute Co-reference &rarr; Parse Co-reference &rarr; <strong>Count Overlap</strong> &rarr; Build Adjacency Matrix &rarr; Run PageRank &rarr; Generate Summary
						</h4>

						<hr />
						
						<ul>
							<li> Build another adjacency Matrix
								$$B_{ij} = \sum\limits_{w \in W} w_iw_j$$
								where $W$ is the set of words we consider for overlapping and $w_i$ is the number of times Word $w$ appears in sentence $i$
							</li>
						</ul>
					</section>
					<section>
						<h2>Algorithm</h2>
						<h4>
							Tokenize &rarr; Compute Co-reference &rarr; Parse Co-reference &rarr; Count Overlap &rarr; <strong>Build Adjacency Matrix</strong> &rarr; Run PageRank &rarr; Generate Summary
						</h4>

						<hr />
						
						<ul>
							<li> 
								The final adjancency Matrix is

								$$ C = k_aA + k_bB $$

								where $k_a, k_b$ are some constants
							</li>
						</ul>
					</section>
					<section>
						<h2>Algorithm</h2>
						<h4>
							Tokenize &rarr; Compute Co-reference &rarr; Parse Co-reference &rarr; Count Overlap &rarr; Build Adjacency Matrix &rarr; <strong>Run PageRank</strong> &rarr; Generate Summary
						</h4>

						<hr />
						
						<ul>
							<li> 
								We run PageRank on $C$ to obtain a PageRank score for all sentences
							</li>
						</ul>
					</section>
					<section>
						<h2>Algorithm</h2>
						<h4>
							Tokenize &rarr; Compute Co-reference &rarr; Parse Co-reference &rarr; Count Overlap &rarr; Build Adjacency Matrix &rarr; Run PageRank &rarr; <strong>Generate Summary</strong>
						</h4>

						<hr />
						
						<ol>
							<li> 
								$S$ is the set of all sentences
							</li>
							<li>
								$R$ is the set of sentences in the summary
							<li>
								Loop while $S \neq \emptyset$
								<ol>
									<li>Pick $s \in S$ such that s has a highest score</li>
									<li>$R = R \cup \{s\}$</li>
									<li>Let $T = \{\text{sentence } i \mid C_{si} > m\}$</li>
									<li>$S = S - T$</li>
									<li>If $R$ exceeds the word limit, trancate the last sentence added to match the word limit</li>
									<li>If $R$ is matches the word limit, terminate the loop</li>
								</ol>
							</li>
							<li>
								Output sentences in $R$ according to their original order in $S$
							</li>
						</ol>
					</section>
					<section>
						<h2>Example</h2>
						<ul class="two-col small">
							<li class="justify">
								<h3>Generated Summary</h3>
							<p>
							we have developed a bootstrapping process for subjectivity classification that explores three ideas : -LRB- 1 -RRB- high - precision classifiers can be used to automatically identify subjective and objective sentences from unannotated texts , -LRB- 2 -RRB- this data can be used as a training set to automatically learn extraction patterns associated with subjectivity , and -LRB- 3 -RRB- the learned patterns can be used to grow the training set , allowing this entire process to be bootstrapped .
							</p>
							<p>
							the performance of the high-precision objective classifier is a bit lower than the subjective classifier : 82.6 % precision and 16.4 % recall on the test set mentioned above -LRB- that is , 82.6 % of the sentences selected by the objective classifier are objective , and the objective classifier found 16.4 % of the objective sentences in the test set -RRB- .
							</p>
							<p>
							the pattern - based subjective sentence classifier classifies a sentence as subjective
							</p>
							<p>
							the labeled sentences are then fed to an extraction pattern learner , which produces a set of extraction patterns that are statistically correlated with the subjective sentences -LRB- we will call these the subjective pat terns -RRB- .
							</p>
							<p>
							in other words , the training set that we used during the second bootstrapping cycle contained exactly the same objective sentences as the first cycle , half of the same subjective sentences as the first cycle , and 9,500 brand new subjective sentences .
							</p>
							</li>
							<li class="justify">
								<h3>Model Summary (Abstract)</h3>
							<p>
							this paper presents a bootstrapping process that learns linguistically rich extraction patterns for subjective ( opinionated ) expressions .
							</p>
							<p>
							high-precision classifiers label unannotated data to automatically create a large training set , which is then given to an extraction pattern learning algorithm .
							</p>
							<p>
							the learned patterns are then used to identify more subjective sentences .
							</p>
							<p>
							the bootstrapping process learns many subjective patterns and increases recall while maintaining high precision .
							</p>
							</li>
						</ul>

					</section>
				</section>
				<section>
					<section>
						<h2>Experiment Setup</h2>
						<ul>
						<li>We use 178 papers in <em>Scholarly Paper Recommendation Dataset</em> from WING, NUS</li>
						<li>The abstracts are used as model summaries and the contents are used as input</li>
						<li>We use ROUGE to evaluate the quality of our summaries based on the abstracts</li>
						<li>For our experiment, we use the R-score from ROUGE since the model summaries do not have a word limit</li>
						<li>For our algorithms, the word limit is set to $200$</li>
						<li>$m$ used in removing overlapping sentences is set to $20$</li>
						</ul>
					</section>
					<section>
											
					<h2>Algorithms</h2>
					<h3>$$ C = k_aA + k_bB $$</h3>
					<ul>
					<li>Random: randomly pick sentences from content</li>
					<li>Degree: $k_a = 0$ (do not consider co-reference), and do not run PageRank, just rank by the degrees</li>
					<li>PageRank: $k_a = 0$ (do not consider co-reference)</li>
					<li>Coref_equal: $k_a = 1, k_b = 1$</li>
					<li>Coref_twice: $k_a = 2, k_b = 1$</li>
					<li>Coref_large: $k_a = 5, k_b = 1$</li>
					<li>Coref_only: $k_a = 1, k_b = 0$ (only consider co-reference)</li>
					</ul>
					</section>
					<section>
						<h2>Results</h2>
						<table>
							<caption>
								Mean values of ROUGE scores
							</caption>
							<tbody>
								<tr>
									<th>Algorighm</th>
									<th>ROUGE-1</th>
									<th>ROUGE-2</th>
									<th>ROUGE-3</th>
									<th>ROUGE-L</th>
								</tr>
								<tr>
									<td>Random</td>
									<td>0.266158</td>
									<td>0.056647</td>
									<td>0.015765</td>
									<td>0.251459</td>
								</tr>
								<tr>
									<td>Degree</td>
									<td>0.302039</td>
									<td>0.079483</td>
									<td>0.023131</td>
									<td>0.279868</td>
								</tr>
								<tr>
									<td>PageRank</td>
									<td>0.308187</td>
									<td>0.080359</td>
									<td>0.024296</td>
									<td>0.285539</td>
								</tr>
								<tr>
									<td>Coref_equal</td>
									<td>0.312450</td>
									<td>0.078048</td>
									<td>0.022415</td>
									<td>0.287519</td>
								</tr>
								<tr>
									<td>Coref_twice</td>
									<td>0.321284</td>
									<td>0.083117</td>
									<td>0.025682</td>
									<td>0.294462</td>
								</tr>
								<tr>
									<td>Coref_large</td>
									<td>0.312604</td>
									<td>0.080656</td>
									<td>0.025286</td>
									<td>0.288393</td>
								</tr>
								<tr>
									<td>Coref_only</td>
									<td>0.287429</td>
									<td>0.072876</td>
									<td>0.022825</td>
									<td>0.268019</td>
								</tr>
							</tbody>	
						</table>
					</section>
					<section>
						<h2>Comparison</h2>

						<p>We perform 1-tailed paired t-tests for ROUGE-L scores of the following algorithms</p>

						<table>
							<tbody>
								<tr>
									<th>Test</th>
									<td>Random &lt; Degree</td>
									<td>Degree &lt; PageRank</td>
									<td>PageRank &lt; Coref_equal</td>
									<td>PageRank &lt; Coref_twice</td>
									<td>PageRank &lt; Coref_large</td>
									<td>Coref_only &lt; PageRank</td>
								</tr>
								<tr>
									<th>p-value</th>
									<td>0.000</td>
									<td>0.055</td>
									<td>0.307</td>
									<td>0.032</td>
									<td>0.307</td>
									<td>0.008</td>
								</tr>
							</tbody>
						</table>
					</section>
				</section>
				<section>
					<section data-markdown>
						## Conclusion

						* The summary quality is reasonable
						* PageRank seems to improve the quality slightly
						* Co-reference can improve the quality
							* but the performance depends on the coefficient
							* and co-reference alone is insufficient
							* it can be that the co-reference data is not good enough
					</section>
				</section>
				<section data-markdown>
					# Q ? A : done();
				</section>
			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: "beige", // available themes are in /css/theme
				transition: "linear", // default/cube/page/concave/zoom/linear/fade/none

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});

			var ticker = 0;
			function retick(){
				clearInterval(ticker);
				ticker = setInterval(function(){
					Reveal.next();
				}, 49000);
			}

			// retick();
			// Reveal.addEventListener('slidechanged', retick);

		</script>

	</body>
</html>
